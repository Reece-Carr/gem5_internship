machine(MachineType:L1Cache, "MSI cache")
 : Sequencer * sequencer;
   CacheMemory * cacheMemory;
   int l2_select_num_bits;
   Cycles l1_request_latency := 1;
   Cycles l1_response_latency := 1;
   Cycles to_l2_latency := 1;
   bool send_evictions;

   // Message Queues
   // From this node's L1 cache TO the network

   // a local L1 -> this L2 bank, currently ordered with directory forwarded requests
   MessageBuffer * requestFromL1Cache, network="To", virtual_network="0",
        vnet_type="request";

   // a local L1 -> this L2 bank
   MessageBuffer * responseFromL1Cache, network="To", virtual_network="1",
        vnet_type="response";

   MessageBuffer * unblockFromL1Cache, network="To", virtual_network="2",
        vnet_type="unblock";


   // To this node's L1 cache FROM the network
   // a L2 bank -> this L1
   MessageBuffer * requestToL1Cache, network="From", virtual_network="2",
        vnet_type="request";

   // a L2 bank -> this L1
   MessageBuffer * responseToL1Cache, network="From", virtual_network="1",
        vnet_type="response";

  // Buffer for requests generated by the processor core.
  MessageBuffer * mandatoryQueue;
{
    state_declaration(State, desc="Cache states") {
        I,      AccessPermission:Invalid,
                    desc="Not present/Invalid";

        IS_D,   AccessPermission:Busy,
                    desc="Invalid, moving to S, waiting for data";
        IM_AD,  AccessPermission:Busy,
                    desc="Invalid, moving to M, waiting for acks and data";
        IM_A,   AccessPermission:Busy,
                    desc="Invalid, moving to M, waiting for acks";

        S,      AccessPermission:Read_Only,
                    desc="Shared. Read-only, other caches may have the block";

        SM_AD,  AccessPermission:Read_Only,
                    desc="Shared, moving to M, waiting for acks and 'data'";
        SM_A,   AccessPermission:Read_Only,
                    desc="Shared, moving to M, waiting for acks";

        M,      AccessPermission:Read_Write,
                    desc="Modified. Read & write permissions. Owner of block";

        MI_A,   AccessPermission:Busy,
                    desc="Was modified, moving to I, waiting for put ack";
        SI_A,   AccessPermission:Busy,
                    desc="Was shared, moving to I, waiting for put ack";
        II_A,   AccessPermission:Busy,
                    desc="Sent valid data before receiving put ack. ";
                         //"Waiting for put ack.";
    }

    enumeration(Event, desc="Cache events") {
        // From the processor/sequencer/mandatory queue
        Load,           desc="Load from processor";
        Store,          desc="Store from processor";

        Replacement,    desc="Triggered when block is chosen as victim";

        FwdGetS,        desc="Directory sent us a request to satisfy GetS. ";
                             //"We must have the block in M to respond to this.";
        FwdGetM,        desc="Directory sent us a request to satisfy GetM. ";
                             //"We must have the block in M to respond to this.";
        Inv,            desc="Invalidate from the directory.";
        PutAck,         desc="Response from directory after we issue a put. ";
                             //"This must be on the fwd network to avoid";
                             //"deadlock.";

        DataDirNoAcks,  desc="Data from directory (acks = 0)";
        DataDirAcks,    desc="Data from directory (acks > 0)";

        DataOwner,      desc="Data from owner";
        InvAck,         desc="Invalidation ack from other cache after Inv";

        LastInvAck,     desc="Triggered after the last ack is received";
    }

    structure(Entry, desc="Cache entry", interface="AbstractCacheEntry") {
        State CacheState,        desc="cache state";
        DataBlock DataBlk,       desc="Data in the block";
    }

    structure(TBE, desc="Entry for transient requests") {
        Addr addr,              desc="Physical address for this TBE";
        State TBEState,         desc="State of block";
        DataBlock DataBlk,      desc="Data for the block. Needed for MI_A";
        int AcksOutstanding, default="0", desc="Number of acks left to receive.";
    }

    structure(TBETable, external="yes") {
      TBE lookup(Addr);
      void allocate(Addr);
      void deallocate(Addr);
      bool isPresent(Addr);
    }

  TBETable TBEs, template="<L1Cache_TBE>", constructor="m_number_of_TBEs";

    int l2_select_low_bit, default="RubySystem::getBlockSizeBits()";

    Tick clockEdge();
    Cycles ticksToCycles(Tick t);
    void set_cache_entry(AbstractCacheEntry a);
    void unset_cache_entry();
    void set_tbe(TBE a);
    void unset_tbe();

    Entry getCacheEntry(Addr address), return_by_pointer="yes" {
        return static_cast(Entry, "pointer", cacheMemory.lookup(address));
    }

    State getState(TBE tbe, Entry cache_entry, Addr addr) {
      if(is_valid(tbe)) {
        return tbe.TBEState;
      } else if (is_valid(cache_entry)) {
        return cache_entry.CacheState;
      }
      return State:I;
    }

    void setState(TBE tbe, Entry cache_entry, Addr addr, State state) {
      if(is_valid(tbe)) {
        tbe.TBEState := state;
      }
      if (is_valid(cache_entry)) {
        cache_entry.CacheState := state;
      }
    }

    AccessPermission getAccessPermission(Addr addr) {
        TBE tbe := TBEs[addr];
        if(is_valid(tbe)) {
            return L1Cache_State_to_permission(tbe.TBEState);
        }

        Entry cache_entry := getCacheEntry(addr);
        if(is_valid(cache_entry)) {
            return L1Cache_State_to_permission(cache_entry.CacheState);
        }

        return AccessPermission:NotPresent;
    }

    void setAccessPermission(Entry cache_entry, Addr addr, State state) {
        if (is_valid(cache_entry)) {
            cache_entry.changePermission(L1Cache_State_to_permission(state));
        }
    }

    void functionalRead(Addr addr, Packet *pkt) {
      TBE tbe := TBEs[addr];
      if(is_valid(tbe)) {
        testAndRead(addr, tbe.DataBlk, pkt);
      } else {
        testAndRead(addr, getCacheEntry(addr).DataBlk, pkt);
      }
    }

    int functionalWrite(Addr addr, Packet *pkt) {
      int num_functional_writes := 0;

      TBE tbe := TBEs[addr];
      if(is_valid(tbe)) {
        num_functional_writes := num_functional_writes +
          testAndWrite(addr, tbe.DataBlk, pkt);
        return num_functional_writes;
      }

      num_functional_writes := num_functional_writes +
          testAndWrite(addr, getCacheEntry(addr).DataBlk, pkt);
      return num_functional_writes;
    }

    out_port(request_out, RequestMsg, requestFromL1Cache);
    out_port(response_out, ResponseMsg, responseFromL1Cache);
    out_port(unblockNetwork_out, ResponseMsg, unblockFromL1Cache);

    in_port(response_in, ResponseMsg, responseToL1Cache, rank = 2) {
        if (response_in.isReady(clockEdge())) {
            peek(response_in, ResponseMsg, block_on="addr") {
                assert(in_msg.Destination.isElement(machineID));
                Entry cache_entry := getCacheEntry(in_msg.addr);
                TBE tbe := TBEs[in_msg.addr];
                assert(is_valid(tbe));

                if (machineIDToMachineType(in_msg.Sender) ==
                            MachineType:L2Cache) {
                    if (in_msg.Type != CoherenceResponseType:DATA) {
                        error("Directory should only reply with data");
                    }
                    assert(tbe.AcksOutstanding - in_msg.AckCount >= 0);
                    if (tbe.AcksOutstanding - in_msg.AckCount == 0) {
                        trigger(Event:DataDirNoAcks, in_msg.addr, cache_entry,
                                tbe);
                    } else {
                        trigger(Event:DataDirAcks, in_msg.addr, cache_entry,
                                tbe);
                    }
                } else {
                    if (in_msg.Type == CoherenceResponseType:DATA) {
                        trigger(Event:DataOwner, in_msg.addr, cache_entry,
                                tbe);
                    } else if (in_msg.Type == CoherenceResponseType:ACK) {
                        if (tbe.AcksOutstanding - in_msg.AckCount == 0) {
                            trigger(Event:LastInvAck, in_msg.addr, cache_entry,
                                    tbe);
                        } else {
                            trigger(Event:InvAck, in_msg.addr, cache_entry,
                                    tbe);
                        }
                    } else {
                        error("Unexpected response from other cache");
                    }
                }
            }
        }
    }

    in_port(forward_in, RequestMsg, requestToL1Cache, rank = 1) {
        if (forward_in.isReady(clockEdge())) {
            peek(forward_in, RequestMsg, block_on="addr") {
                assert(in_msg.Destination.isElement(machineID));
                Entry cache_entry := getCacheEntry(in_msg.addr);
                TBE tbe := TBEs[in_msg.addr];

                if (in_msg.Type == CoherenceRequestType:GETS) {
                    trigger(Event:FwdGetS, in_msg.addr, cache_entry, tbe);
                } else if (in_msg.Type == CoherenceRequestType:GETX) {
                    trigger(Event:FwdGetM, in_msg.addr, cache_entry, tbe);
                } else if (in_msg.Type == CoherenceRequestType:INV) {
                    trigger(Event:Inv, in_msg.addr, cache_entry, tbe);
                } else if (in_msg.Type == CoherenceRequestType:WB_ACK) {
                    trigger(Event:PutAck, in_msg.addr, cache_entry, tbe);
                } else {
                    error("Unexpected forward message!");
                }
            }
        }
    }

    in_port(mandatory_in, RubyRequest, mandatoryQueue, desc="...", rank = 0) {
        if (mandatory_in.isReady(clockEdge())) {
            peek(mandatory_in, RubyRequest, block_on="LineAddress") {
                Entry cache_entry := getCacheEntry(in_msg.LineAddress);
                if (is_invalid(cache_entry) &&
                        cacheMemory.cacheAvail(in_msg.LineAddress) == false ) {
                    Addr addr := cacheMemory.cacheProbe(in_msg.LineAddress);
                    Entry victim_entry := getCacheEntry(addr);
                    TBE victim_tbe := TBEs[addr];
                    trigger(Event:Replacement, addr, victim_entry, victim_tbe);
                } else {
                    if (in_msg.Type == RubyRequestType:LD ||
                            in_msg.Type == RubyRequestType:IFETCH) {
                        trigger(Event:Load, in_msg.LineAddress, cache_entry,
                                TBEs[in_msg.LineAddress]);
                    } else if (in_msg.Type == RubyRequestType:ST) {
                        trigger(Event:Store, in_msg.LineAddress, cache_entry,
                                TBEs[in_msg.LineAddress]);
                    } else {
                        error("Unexpected type from processor");
                    }
                }
            }
        }
    }

    action(sendGetS, 'gS', desc="Send GetS to the directory") {
      peek(mandatory_in, RubyRequest) {
        enqueue(request_out, RequestMsg, 1) {
            out_msg.addr := address;
            out_msg.Type := CoherenceRequestType:GETS;
            out_msg.Destination.add(mapAddressToRange(address, MachineType:L2Cache,
                              l2_select_low_bit, l2_select_num_bits, intToID(0)));
            out_msg.MessageSize := MessageSizeType:Control;
            out_msg.Requestor := machineID;
        }
      }
    }

    action(sendGetM, "gM", desc="Send GetM to the directory") {
      peek(mandatory_in, RubyRequest) {
        enqueue(request_out, RequestMsg, 1) {
            out_msg.addr := address;
            out_msg.Type := CoherenceRequestType:GETX;
            out_msg.Destination.add(mapAddressToRange(address, MachineType:L2Cache,
                              l2_select_low_bit, l2_select_num_bits, intToID(0)));
            out_msg.MessageSize := MessageSizeType:Control;
            out_msg.Requestor := machineID;
        }
      }
    }

    // NOTE: Clean evict. Required to keep the directory state up-to-date
    action(sendPutS, "pS", desc="Send PutS to the directory") {
        enqueue(request_out, RequestMsg, 1) {
            out_msg.addr := address;
            out_msg.Type := CoherenceRequestType:PUTS;
            out_msg.Dirty := false;
            out_msg.Destination.add(mapAddressToRange(address, MachineType:L2Cache,
                              l2_select_low_bit, l2_select_num_bits, intToID(0)));
            out_msg.MessageSize := MessageSizeType:Writeback_Control;
            out_msg.Requestor := machineID;
        }
    }

    action(sendPutM, "pM", desc="Send putM+data to the directory") {
        enqueue(request_out, RequestMsg, 1) {
            out_msg.addr := address;
            out_msg.Type := CoherenceRequestType:PUTX;
            out_msg.Destination.add(mapAddressToRange(address, MachineType:L2Cache,
                              l2_select_low_bit, l2_select_num_bits, intToID(0)));
            out_msg.DataBlk := cache_entry.DataBlk;
            out_msg.Dirty := true;
            out_msg.MessageSize := MessageSizeType:Writeback_Data;
            out_msg.Requestor := machineID;
        }
    }

    action(sendCacheDataToReq, "cdR", desc="Send cache data to requestor") {
        assert(is_valid(cache_entry));
        peek(forward_in, RequestMsg) {
            enqueue(response_out, ResponseMsg, 1) {
                out_msg.addr := address;
                out_msg.Type := CoherenceResponseType:DATA;
                out_msg.Destination.add(in_msg.Requestor);
                out_msg.DataBlk := cache_entry.DataBlk;
                out_msg.Dirty := true;
                out_msg.MessageSize := MessageSizeType:Response_Data;
                out_msg.Sender := machineID;
            }
        }
    }

    action(sendCacheDataToDir, "cdD", desc="Send the cache data to the dir") {
        enqueue(response_out, ResponseMsg, 1) {
            out_msg.addr := address;
            out_msg.Type := CoherenceResponseType:DATA;
            out_msg.Destination.add(mapAddressToRange(address, MachineType:L2Cache,
                              l2_select_low_bit, l2_select_num_bits, intToID(0)));
            out_msg.DataBlk := cache_entry.DataBlk;
            out_msg.Dirty := true;
            out_msg.MessageSize := MessageSizeType:Response_Data;
            out_msg.Sender := machineID;
        }
    }

    action(sendInvAcktoReq, "iaR", desc="Send inv-ack to requestor") {
        peek(forward_in, RequestMsg) {
            enqueue(response_out, ResponseMsg, 1) {
                out_msg.addr := address;
                out_msg.Type := CoherenceResponseType:ACK;
                out_msg.Destination.add(in_msg.Requestor);
                out_msg.MessageSize := MessageSizeType:Response_Control;
                out_msg.Sender := machineID;
                out_msg.AckCount := 1;
            }
        }
    }

    action(decrAcks, "da", desc="Decrement the number of acks") {
        assert(is_valid(tbe));
        tbe.AcksOutstanding := tbe.AcksOutstanding - 1;
        // This annotates the protocol trace
        APPEND_TRANSITION_COMMENT("Acks: ");
        APPEND_TRANSITION_COMMENT(tbe.AcksOutstanding);
    }

    action(storeAcks, "sa", desc="Store the needed acks to the TBE") {
        assert(is_valid(tbe));
        peek(response_in, ResponseMsg) {
            tbe.AcksOutstanding := tbe.AcksOutstanding - in_msg.AckCount;
        }
        APPEND_TRANSITION_COMMENT("Acks: ");
        APPEND_TRANSITION_COMMENT(tbe.AcksOutstanding);
        assert(tbe.AcksOutstanding > 0);
    }

    // Responses to CPU requests (e.g., hits and store acks)
    action(loadHit, "Lh", desc="Load hit") {
        assert(is_valid(cache_entry));
        // Set this entry as the most recently used for the replacement policy
        cacheMemory.setMRU(cache_entry);
        // Send the data back to the sequencer/CPU. NOTE: False means it was
        // not an "external hit", but hit in this local cache.
        sequencer.readCallback(address, cache_entry.DataBlk);
    }

    action(externalLoadHit, "xLh", desc="External load hit (was a miss)") {
        assert(is_valid(cache_entry));
        cacheMemory.setMRU(cache_entry);
        // Forward the type of machine that responded to this request
        // E.g., another cache or the directory. This is used for tracking
        // statistics.
        sequencer.readCallback(address, cache_entry.DataBlk, true);
    }

    action(storeHit, "Sh", desc="Store hit") {
        assert(is_valid(cache_entry));
        cacheMemory.setMRU(cache_entry);
        // The same as the read callback above.
        sequencer.writeCallback(address, cache_entry.DataBlk);
    }

    action(externalStoreHit, "xSh", desc="External store hit (was a miss)") {
        assert(is_valid(cache_entry));
        cacheMemory.setMRU(cache_entry);
        sequencer.writeCallback(address, cache_entry.DataBlk, true);
    }

    action(forwardEviction, "e", desc="sends eviction notification to CPU") {
        if (send_evictions) {
            sequencer.evictionCallback(address);
        }
    }

    // Cache management actions
    action(allocateCacheBlock, "a", desc="Allocate a cache block") {
        //assert(is_invalid(cache_entry));
        //assert(cacheMemory.cacheAvail(address));
        //// Create a new entry and update cache_entry to the new entry
        //set_cache_entry(cacheMemory.allocate(address, new Entry));
        if (is_invalid(cache_entry)) {
          set_cache_entry(cacheMemory.allocate(address, new Entry));
        }
    }

    action(deallocateCacheBlock, "d", desc="Deallocate a cache block") {
        assert(is_valid(cache_entry));
        cacheMemory.deallocate(address);
        // clear the cache_entry variable (now it's invalid)
        unset_cache_entry();
    }

    action(writeDataToCache, "wd", desc="Write data to the cache") {
        peek(response_in, ResponseMsg) {
            assert(is_valid(cache_entry));
            cache_entry.DataBlk := in_msg.DataBlk;
        }
    }

    action(allocateTBE, "aT", desc="Allocate TBE") {
      check_allocate(TBEs);
      assert(is_valid(cache_entry));
      TBEs.allocate(address);
      set_tbe(TBEs[address]);
      tbe.DataBlk := cache_entry.DataBlk;
    }

    action(deallocateTBE, "dT", desc="Deallocate TBE") {
        assert(is_valid(tbe));
        TBEs.deallocate(address);
        // this makes the tbe varible invalid
        unset_tbe();
    }

    // Queue management actions
    action(popMandatoryQueue, "pQ", desc="Pop the mandatory queue") {
        mandatory_in.dequeue(clockEdge());
    }

    action(popResponseQueue, "pR", desc="Pop the response queue") {
        response_in.dequeue(clockEdge());
    }

    action(popForwardQueue, "pF", desc="Pop the forward queue") {
        forward_in.dequeue(clockEdge());
    }

    // Stalling actions
    action(stall, "z", desc="Stall the incoming request") {
        // Do nothing. However, the transition must have some action to be
        // valid which is why this is needed.
        // NOTE: There are other more complicated but higher performing stalls
        // in Ruby like recycle() or stall_and_wait.
        // z_stall stalls everything in the queue behind this request.
    }

    transition(I, Load, IS_D) {
        allocateCacheBlock;
        allocateTBE;
        sendGetS;
        popMandatoryQueue;
    }

    transition(I, Store, IM_AD) {
        allocateCacheBlock;
        allocateTBE;
        sendGetM;
        popMandatoryQueue;
    }

    transition(IS_D, {Load, Store, Replacement, Inv}) {
        stall;
    }

    transition(IS_D, {DataDirNoAcks, DataOwner}, S) {
        writeDataToCache;
        deallocateTBE;
        externalLoadHit;
        popResponseQueue;
    }

    transition({IM_AD, IM_A}, {Load, Store, Replacement, FwdGetS, FwdGetM}) {
        stall;
    }

    transition({IM_AD, IM_A}, Inv) {
        sendInvAcktoReq;
        popForwardQueue;
    }

    transition({IM_AD, SM_AD}, {DataDirNoAcks, DataOwner}, M) {
        writeDataToCache;
        deallocateTBE;
        externalStoreHit;
        popResponseQueue;
    }

    transition(IM_AD, DataDirAcks, IM_A) {
        writeDataToCache;
        storeAcks;
        popResponseQueue;
    }

    transition({IM_AD, IM_A, SM_AD, SM_A}, InvAck) {
        decrAcks;
        popResponseQueue;
    }

    transition({IM_A, SM_A}, LastInvAck, M) {
        deallocateTBE;
        externalStoreHit;
        popResponseQueue;
    }

    transition({S,M}, Load) {
        loadHit;
        popMandatoryQueue;
    }

    transition(S, Store, SM_AD) {
        allocateTBE;
        sendGetM;
        popMandatoryQueue;
    }

    transition(S, Replacement, SI_A) {
        forwardEviction;
        sendPutS;
    }

    transition(S, Inv, I) {
        //forwardEviction;
        sendInvAcktoReq;
        deallocateCacheBlock;
        popForwardQueue;
    }

    transition(M, Inv, I) {
        forwardEviction;
        sendCacheDataToDir;
        deallocateCacheBlock;
        popForwardQueue;
    }

    transition(MI_A, Inv, II_A) {
        sendCacheDataToDir;
        popForwardQueue;
    }

    transition({SM_AD, SM_A}, {Load, Store, Replacement, FwdGetS, FwdGetM}) {
        stall;
    }

    transition(SM_AD, Inv, IM_AD) {
        forwardEviction; // Should this be here to squash speculative reads?
        sendInvAcktoReq;
        popForwardQueue;
    }

    transition(SM_AD, DataDirAcks, SM_A) {
        writeDataToCache;
        storeAcks;
        popResponseQueue;
    }

    transition(M, Store) {
        storeHit;
        popMandatoryQueue;
    }

    transition(M, Replacement, MI_A) {
        forwardEviction;
        sendPutM;
    }

    transition(M, FwdGetS, S) {
        sendCacheDataToReq;
        sendCacheDataToDir;
        popForwardQueue;
    }

    transition(M, FwdGetM, I) {
        forwardEviction;
        sendCacheDataToReq;
        deallocateCacheBlock;
        popForwardQueue;
    }

    transition({MI_A, SI_A, II_A}, {Load, Store, Replacement}) {
        stall;
    }

    transition(MI_A, FwdGetS, SI_A) {
        sendCacheDataToReq;
        sendCacheDataToDir;
        popForwardQueue;
    }

    transition(MI_A, FwdGetM, II_A) {
        sendCacheDataToReq;
        popForwardQueue;
    }

    transition({MI_A, SI_A, II_A}, PutAck, I) {
        deallocateCacheBlock;
        popForwardQueue;
    }

    transition(SI_A, Inv, II_A) {
        sendInvAcktoReq;
        popForwardQueue;
    }

}
